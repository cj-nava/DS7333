median_windowed_ASE.4_weeks = median(ASEHolder.4_weeks)
# visualization of windowed ASE over time
par(mar = c(5,5,2,5))
plot(ts.log_flu, type="l", ylab='Flu Positive Rate', xlab='Time', las = 1, col="blue", main = 'Figure 12 \nRolling Window ASE Over Time (4-week forecast)')
par(new = T)
# plot rolling window ASE
plot(ASEHolder.4_weeks, type="l", lty=2, axes=F, ylab=NA, xlab=NA, col="red")
# create tick marks and label on right vertical axis
axis(side=4, las=1)
# add ASE line
mtext(side=4, line=3, 'ASE')
# add legend
legend("topleft", legend=c("Obs. Value", "ASE"), lty=c(1, 2), col=c("blue", "red"), cex=.6)
horizon = 12 # we forecast out 3 months, or 12 weeks
ASEHolder.3_months = numeric() # this is an empty varible that will hold all the ASE values
for( i in 1:(260-(trainingSize + horizon) + 1))
{
forecasts = fore.aruma.wge(ts.log_flu[i:(i+(trainingSize-1))],
phi = phis, theta = thetas,
s = s, d = d, n.ahead = horizon,plot=FALSE)
ASE = mean((ts.log_flu[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2)
ASEHolder.3_months[i] = ASE
}
mean_windowed_ASE.3_months = mean(ASEHolder.3_months)
median_windowed_ASE.3_months = median(ASEHolder.3_months)
# visualization of windowed ASE over time
par(mar = c(5,5,2,5))
plot(ts.log_flu, type="l", ylab='Flu Positive Rate', xlab='Time', las = 1, col="blue", main = 'Figure 13 \nRolling Window ASE Over Time (3-month forecast)')
par(new = T)
# plot rolling window ASE
plot(ASEHolder.3_months, type="l", lty=2, axes=F, ylab=NA, xlab=NA, col="red")
# create tick marks and label on right vertical axis
axis(side=4, las=1)
# add ASE line
mtext(side=4, line=3, 'ASE')
# add legend
legend("topleft", legend=c("Obs. Value", "ASE"), lty=c(1, 2), col=c("blue", "red"), cex=.6)
horizon = 26 # we forecast out 6 months, or 26 weeks
ASEHolder.6_months = numeric() # this is an empty varible that will hold all the ASE values
for( i in 1:(260-(trainingSize + horizon) + 1))
{
forecasts = fore.aruma.wge(ts.log_flu[i:(i+(trainingSize-1))],
phi = phis, theta = thetas,
s = s, d = d, n.ahead = horizon,plot=FALSE)
ASE = mean((ts.log_flu[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2)
ASEHolder.6_months[i] = ASE
}
mean_windowedASE.6_months = mean(ASEHolder.6_months)
median_windowedASE.6_months = median(ASEHolder.6_months)
# visualization of windowed ASE over time
newASE = c(rep(NA, 131), ASEHolder.6_months) # this plots ASE from week 131 onward
par(mar = c(5,5,2,5))
plot(ts.log_flu, type="l", ylab='Flu Positive Rate', xlab='Time', las = 1, col="blue", main = 'Figure 14 \nRolling Window ASE Over Time (6-month forecast)')
par(new = T)
# plot rolling window ASE
plot(ASEHolder.6_months, type="l", lty=2, axes=F, ylab=NA, xlab=NA, col="red")
# create tick marks and label on right vertical axis
axis(side=4, las=1)
# add ASE line
mtext(side=4, line=3, 'ASE')
# add legend
legend("topleft", legend=c("Obs. Value", "ASE"), lty=c(1, 2), col=c("blue", "red"), cex=.6)
horizon = 52 # we forecast out 1 year, or 52 weeks
ASEHolder.1_year = numeric() # this is an empty varible that will hold all the ASE values
for( i in 1:(260-(trainingSize + horizon) + 1))
{
forecasts = fore.aruma.wge(ts.log_flu[i:(i+(trainingSize-1))],
phi = phis, theta = thetas,
s = s, d = d, n.ahead = horizon,plot=FALSE)
ASE = mean((ts.log_flu[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2)
ASEHolder.1_year[i] = ASE
}
mean_windowedASE.1_year = mean(ASEHolder.1_year)
median_windowedASE.1_year = median(ASEHolder.1_year)
# visualization of windowed ASE over time
par(mar = c(5,5,2,5))
plot(ts.log_flu, type="l", ylab='Flu Positive Rate', xlab='Time', las = 1, col="blue", main = 'Figure 15 \nRolling Window ASE Over Time (1-year forecast)')
par(new = T)
# plot rolling window ASE
plot(ASEHolder.1_year, type="l", lty=2, axes=F, ylab=NA, xlab=NA, col="red")
# create tick marks and label on right vertical axis
axis(side=4, las=1)
# add ASE line
mtext(side=4, line=3, 'ASE')
# add legend
legend("topleft", legend=c("Obs. Value", "ASE"), lty=c(1, 2), col=c("blue", "red"), cex=.6)
single_ASE.2_weeks = tail(ASEHolder.2_weeks, n=1)
single_ASE.4_weeks = tail(ASEHolder.4_weeks, n=1)
single_ASE.3_months = tail(ASEHolder.3_months, n=1)
single_ASE.6_months = tail(ASEHolder.6_months, n=1)
single_ASE.1_year = tail(ASEHolder.1_year, n=1)
forecast_horizon <- c("2 weeks", "4 weeks", "3 months", "6 months", "1 year")
single_ASE <- c(single_ASE.2_weeks, single_ASE.4_weeks, single_ASE.3_months, single_ASE.6_months, single_ASE.1_year)
mean_rolling_window_ASE<- c(mean_windowed_ASE.2_weeks,mean_windowed_ASE.4_weeks, mean_windowed_ASE.3_months, mean_windowedASE.6_months, mean_windowedASE.1_year)
median_rolling_window_ASE <- c(median_windowed_ASE.2_weeks, median_windowed_ASE.4_weeks, median_windowed_ASE.3_months, median_windowedASE.6_months, median_windowedASE.1_year)
rolling.window.ASE <- data.frame(forecast_horizon, single_ASE, mean_rolling_window_ASE, median_rolling_window_ASE)
names(rolling.window.ASE)[names(rolling.window.ASE) == "forecast_horizon"] <- "Forecast Horizon"
names(rolling.window.ASE)[names(rolling.window.ASE) == "single_ASE"] <- "Single ASE"
names(rolling.window.ASE)[names(rolling.window.ASE) == "mean_rolling_window_ASE"] <- "Rolling Window ASE (Mean)"
names(rolling.window.ASE)[names(rolling.window.ASE) == "median_rolling_window_ASE"] <- "Rolling Window ASE (Median)"
customGreen0 = "#DeF7E9"
customGreen = "#71CA97"
formattable(rolling.window.ASE, align =c("l","c","c"), list(
`Forecast Horizon` = formatter("span", style = ~ style(color = "grey",font.weight = "bold")),
`Single ASE`= color_tile(customGreen, customGreen0),
`Rolling Window ASE (Mean)`= color_tile(customGreen, customGreen0),
`Rolling Window ASE (Median)`= color_tile(customGreen, customGreen0)
))
install.packages(c("skimr", "VIM"))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(VIM)
library(skimr)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(VIM)
library(skimr)
# loading data set
boston.df <- read.csv("https://raw.githubusercontent.com/jotsap/DS7333/master/data/boston.csv", header = T)
#explore dataframe
str(boston.df)
head(boston.df)
summary(boston.df)
#skim dataframe
skim(boston.df)
# from VIM package
aggr(boston.df,
prop = FALSE,
combined = TRUE,
numbers = TRUE,
sortVars = TRUE,
sortCombs = TRUE)
# initial full regression
boston.lm <- lm( MEDV ~ . , data = boston.df, na.action = na.omit  )
summary(boston.lm)
# replace set to FALSE ensures no repeating numbers in sample vector
# 1% - 5 entries
base::sample(1:506, 5, replace = F) -> index_01
# 5% - 25 entires
base::sample(1:506, 25, replace = F) -> index_05
# 10% - 50 entires
base::sample(1:506, 51, replace = F) -> index_10
# 20% - 100 entries
base::sample(1:506, 102, replace = F) -> index_20
# 33% - 165 entries
base::sample(1:506, 168, replace = F) -> index_33
# 50% - 250 entries
base::sample(1:506, 253, replace = F) -> index_50
# replace set to FALSE ensures no repeating numbers in sample vector
# 1% - 5 entries
base::sample(1:506, 5, replace = F) -> index_01
# 5% - 25 entires
base::sample(1:506, 25, replace = F) -> index_05
# 10% - 50 entires
base::sample(1:506, 51, replace = F) -> index_10
# 20% - 100 entries
base::sample(1:506, 102, replace = F) -> index_20
# 33% - 165 entries
base::sample(1:506, 168, replace = F) -> index_33
# 50% - 250 entries
base::sample(1:506, 253, replace = F) -> index_50
plot(MEDV ~ ., data = boston.df)
abline(boston.lm)
plot(boston.lm$fitted, boston.lm$residuals, xlab = "Fitted Values", ylab = "Residuals")
abline(0,0)
plot(boston.lm$fitted, boston.lm$residuals, xlab = "Fitted Values", ylab = "Residuals")
abline(0,0)
deviance(boston.lm)
plot(boston.lm$fitted, boston.lm$residuals, xlab = "Fitted Values", ylab = "Residuals")
abline(0,0)
deviance(boston.lm)
residuals(boston.lm)
---
title: "unit10_boston-housing"
author: "Martin Garcia, Michael Catalano, Jeremy Otsap, Christian Nava"
date: "6/26/2020"
output:
html_document:
keep_md: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(VIM)
library(skimr)
```
## Boston Data Set
Using the Boston Housing Data Set examine the effect on loss for data Missing Completely at Random for 10% 20% and 50% of the data. Repeat the analysis for Missing at random and Missing Not at random.
MCAR
MAR
Monotone
**https://www.kaggle.com/puxama/bostoncsv**
https://www.kaggle.com/c/boston-housing
https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html
##Initial Data Exploration
**Data Description**
The Boston data frame has 506 rows and 14 columns.
This data frame contains the following columns:
* CRIM - per capita crime rate by town
* ZN - proportion of residential land zoned for lots over 25,000 sq.ft.
* INDUS - proportion of non-retail business acres per town.
* CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)
* NOX - nitric oxides concentration (parts per 10 million)
* RM - average number of rooms per dwelling
* AGE - proportion of owner-occupied units built prior to 1940
* DIS - weighted distances to five Boston employment centres
* RAD - index of accessibility to radial highways
* TAX - full-value property-tax rate per $10,000
* PTRATIO - pupil-teacher ratio by town
* B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
* LSTAT - % lower status of the population
* MEDV - Median value of owner-occupied homes in $1000's
**Importing Data**
```{r, echo=FALSE}
# loading data set
boston.df <- read.csv("https://raw.githubusercontent.com/jotsap/DS7333/master/data/boston.csv", header = T)
```
**Cursory Data Exploration**
```{r, echo=FALSE}
#explore dataframe
str(boston.df)
head(boston.df)
summary(boston.df)
```
Skim allows a quick visual examination of each variable's range
```{r, echo=FALSE}
#skim dataframe
skim(boston.df)
```
**Missing Data**
No missing values found
```{r, echo=FALSE}
# from VIM package
aggr(boston.df,
prop = FALSE,
combined = TRUE,
numbers = TRUE,
sortVars = TRUE,
sortCombs = TRUE)
```
##Initial Regression Model
We are doing a regression on full data set, predicting MEDV, the median value of owner-occupied homes, using the other 13 parameters.
**Exclude vs Omit**
Using na.exclude pads the residuals and fitted values with NAs where there were missing values. Other functions do not use the na.action, but instead have a different argument (with some default) for how they will handle missing values. For example, the mean command will, by default, return NA if there are any NAs in the passed object.
```{r, echo=FALSE}
# initial full regression
boston.lm <- lm( MEDV ~ . , data = boston.df, na.action = na.omit  )
summary(boston.lm)
```
```{r}
plot(boston.lm$fitted, boston.lm$residuals, xlab = "Fitted Values", ylab = "Residuals")
abline(0,0)
deviance(boston.lm)
head(residuals(boston.lm))
```
**RESULTS**
For "goodness of fit" we ;ppl at the adjusted R-squared value [which penalizes for large numbers of predictors, and get a score of 0.7338. Which means roughly 73.4% of the MEDV response variable is accounted for by the other 13 predictors.
NOTE: Because AGE and INDUS were found to not be statistically significant we will *not* use those for the missing data exercises
Coefficients:
Estimate Std. Error t value Pr(>|t|)
(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***
CRIM        -1.080e-01  3.286e-02  -3.287 0.001087 **
ZN           4.642e-02  1.373e-02   3.382 0.000778 ***
INDUS        2.056e-02  6.150e-02   0.334 0.738288
CHAS         2.687e+00  8.616e-01   3.118 0.001925 **
NOX         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***
RM           3.810e+00  4.179e-01   9.116  < 2e-16 ***
AGE          6.922e-04  1.321e-02   0.052 0.958229
DIS         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***
RAD          3.060e-01  6.635e-02   4.613 5.07e-06 ***
TAX         -1.233e-02  3.760e-03  -3.280 0.001112 **
PTRATIO     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***
B            9.312e-03  2.686e-03   3.467 0.000573 ***
LSTAT       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***
##MCAR
First generate vector of *unique* random numbers to correspond to each percentage
* 1% - 5 entries
* 5% - 25 entries
* 10% - 51 entries
* 20% - 102 entries
* 33% - 168 entries
* 50% - 253 entries
**Value to be Deleted**
* PTRATIO - pupil-teacher ratio by town
Create vector to serve as sample index for creating NA values
```{r, echo=FALSE}
# replace set to FALSE ensures no repeating numbers in sample vector
# 1% - 5 entries
base::sample(1:506, 5, replace = F) -> index_01
# 5% - 25 entires
base::sample(1:506, 25, replace = F) -> index_05
# 10% - 50 entires
base::sample(1:506, 51, replace = F) -> index_10
# 20% - 100 entries
base::sample(1:506, 102, replace = F) -> index_20
# 33% - 165 entries
base::sample(1:506, 168, replace = F) -> index_33
# 50% - 250 entries
base::sample(1:506, 253, replace = F) -> index_50
```
**Create different boston samples with NA for PTRATIO**
1% - 5 entries
```{r, echo=FALSE}
# create separate file
boston.df -> boston_mcar_01.df
# assign NA to PTRATIO
boston_mcar_01.df[index_01,'PTRATIO'] <- NA
# validate results
head(boston_mcar_01.df[index_01,'PTRATIO'])
aggr(boston_mcar_01.df,
prop = FALSE,
combined = TRUE,
numbers = TRUE,
sortVars = TRUE,
sortCombs = TRUE)
```
5% - 25 entries
```{r, echo=FALSE}
# create separate file
boston.df -> boston_mcar_05.df
# assign NA to PTRATIO
boston_mcar_05.df[index_05,'PTRATIO'] <- NA
# validate results
head(boston_mcar_05.df[index_05,'PTRATIO'])
aggr(boston_mcar_05.df,
prop = FALSE,
combined = TRUE,
numbers = TRUE,
sortVars = TRUE,
sortCombs = TRUE)
```
10% - 51 entries
```{r, echo=FALSE}
# create separate file
boston.df -> boston_mcar_10.df
# assign NA to PTRATIO
boston_mcar_10.df[index_10,'PTRATIO'] <- NA
# validate results
head(boston_mcar_10.df[index_10,'PTRATIO'])
aggr(boston_mcar_10.df,
prop = FALSE,
combined = TRUE,
numbers = TRUE,
sortVars = TRUE,
sortCombs = TRUE)
```
20% - 102 entries
```{r, echo=FALSE}
# create separate file
boston.df -> boston_mcar_20.df
# assign NA to PTRATIO
boston_mcar_20.df[index_20,'PTRATIO'] <- NA
# validate results
head(boston_mcar_20.df[index_20,'PTRATIO'])
aggr(boston_mcar_20.df,
prop = FALSE,
combined = TRUE,
numbers = TRUE,
sortVars = TRUE,
sortCombs = TRUE)
```
33% - 168 entries
```{r, echo=FALSE}
# create separate file
boston.df -> boston_mcar_33.df
# assign NA to PTRATIO
boston_mcar_33.df[index_33,'PTRATIO'] <- NA
# validate results
head(boston_mcar_33.df[index_33,'PTRATIO'])
aggr(boston_mcar_33.df,
prop = FALSE,
combined = TRUE,
numbers = TRUE,
sortVars = TRUE,
sortCombs = TRUE)
```
50% - 253 entries
```{r, echo=FALSE}
# create separate file
boston.df -> boston_mcar_50.df
# assign NA to PTRATIO
boston_mcar_50.df[index_50,'PTRATIO'] <- NA
# validate results
head(boston_mcar_50.df[index_50,'PTRATIO'])
aggr(boston_mcar_50.df,
prop = FALSE,
combined = TRUE,
numbers = TRUE,
sortVars = TRUE,
sortCombs = TRUE)
```
```{r, echo=FALSE}
#
```
##MAR
**Determining Parameter for Deletion**
* 10%: TAX <= 233 – [54 values 10.67%]
* 20%: TAX <= 270 – [99 values 19.565%]
* 30%: TAX <= 287 – [149 values 29.447%]
**Values to be Deleted**
* CRIM - per capita crime rate by town
* RAD - index of accessibility to radial highways
###MAR 10%
```{r, echo=FALSE}
# create 10% MAR dataframe
boston.df -> boston_mar_10.df
# list rows with TAX <= 233
boston_mar_10.df[boston_mar_10.df$TAX <= 233,c("CRIM","RAD")]
```
```{r, echo=FALSE}
#assign NA to CRIM for 10% MAR
boston_mar_10.df$CRIM[boston_mar_10.df$TAX <= 233] <- NA
#assign NA to RAD for 10% MAR
boston_mar_10.df$RAD[boston_mar_10.df$TAX <= 233] <- NA
```
```{r, echo=FALSE}
# list rows with missing values
boston_mar_10.df[is.na(boston_mar_10.df$CRIM),c("CRIM","RAD","TAX")]
# list rows with TAX <= 233
boston_mar_10.df[boston_mar_10.df$TAX <= 233, c("CRIM","RAD")]
```
###MAR 20%
```{r, echo=FALSE}
# create 10% MAR dataframe
boston.df -> boston_mar_20.df
# list rows with TAX <= 233
boston_mar_20.df[boston_mar_20.df$TAX <= 270,c("CRIM","RAD")]
```
```{r, echo=FALSE}
#assign NA to CRIM for 10% MAR
boston_mar_20.df$CRIM[boston_mar_20.df$TAX <= 270] <- NA
#assign NA to RAD for 10% MAR
boston_mar_20.df$RAD[boston_mar_20.df$TAX <= 270] <- NA
```
```{r, echo=FALSE}
# list rows with missing values
boston_mar_20.df[is.na(boston_mar_20.df$CRIM),c("CRIM","RAD","TAX")]
# list rows with TAX <= 233
boston_mar_20.df[boston_mar_20.df$TAX <= 270, c("CRIM","RAD")]
```
###MAR 30%
```{r, echo=FALSE}
# create 10% MAR dataframe
boston.df -> boston_mar_30.df
# list rows with TAX <= 233
boston_mar_30.df[boston_mar_30.df$TAX <= 287,c("CRIM","RAD")]
```
```{r, echo=FALSE}
#assign NA to CRIM for 10% MAR
boston_mar_30.df$CRIM[boston_mar_30.df$TAX <= 287] <- NA
#assign NA to RAD for 10% MAR
boston_mar_30.df$RAD[boston_mar_30.df$TAX <= 287] <- NA
```
```{r, echo=FALSE}
# list rows with missing values
boston_mar_30.df[is.na(boston_mar_30.df$CRIM),c("CRIM","RAD","TAX")]
# list rows with TAX <= 233
boston_mar_30.df[boston_mar_30.df$TAX <= 287, c("CRIM","RAD")]
```
```{r, echo=FALSE}
#
```
```{r, echo=FALSE}
#
```
plot(boston.lm$fitted, boston.lm$residuals, xlab = "Fitted Values", ylab = "Residuals")
abline(0,0)
deviance(boston.lm)
head(residuals(boston.lm))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(VIM)
library(skimr)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(VIM)
library(skimr)
# loading data set
boston.df <- read.csv("https://raw.githubusercontent.com/jotsap/DS7333/master/data/boston.csv", header = T)
#explore dataframe
str(boston.df)
head(boston.df)
summary(boston.df)
#skim dataframe
skim(boston.df)
# from VIM package
aggr(boston.df,
prop = FALSE,
combined = TRUE,
numbers = TRUE,
sortVars = TRUE,
sortCombs = TRUE)
# initial full regression
boston.lm <- lm( MEDV ~ . , data = boston.df, na.action = na.omit  )
summary(boston.lm)
plot(boston.lm$fitted, boston.lm$residuals, xlab = "Fitted Values", ylab = "Residuals")
abline(0,0)
deviance(boston.lm)
head(residuals(boston.lm))
plot(boston.lm$fitted, boston.lm$residuals, xlab = "Fitted Values", ylab = "Residuals")
abline(0,0)
deviance(boston.lm)
head(residuals(boston.lm))
summary(boston.lm)
plot(boston.lm$fitted, boston.lm$residuals, xlab = "Fitted Values", ylab = "Residuals")
abline(0,0)
deviance(boston.lm)
head(residuals(boston.lm))
summary(boston.lm)
plot(boston.lm$fitted, boston.lm$residuals, xlab = "Fitted Values", ylab = "Residuals")
abline(0,0)
deviance(boston.lm)
